# Applied-AI-Study-Group

This is the repository for the content of inzva 2020-June Applied AI Study Group, guided by Ahmet Melek and Onur Boyar.

In the group we have worked on these subjects:

* Frameworks: Tensorflow, Keras Functional API, Keras Sequential API, Pytorch

* Topics: Image Classification, Image Localisation, Image Segmentation

* Architectures - Methods: Artificial Neural Networks (Fully-Connected Neural Networks), Convolutional Neural Networks (CNN)

* Environments: Google Colab, Jupyter Notebook (Local)

## Weekly Summaries

### Week1 - Computer Vision

We have worked on six problems:

* Image Classification with MNIST dataset on tensorflow, using Fully-Connected Neural Networks.

* Image Classification with MNIST dataset on keras functional API, using Convolutional Neural Networks.

* Image Classification with CIFAR-10 dataset on keras sequential API, using Convolutional Neural Networks.

* Image Localisation with Kaggle Facial Keypoint Detection dataset on keras sequential API, using Convolutional Neural Networks.

* Image Localisation with Kaggle Facial Keypoint Detection dataset on Pytorch, using Convolutional Neural Networks.

* Image Segmentation with testing on random images from internet on Pytorch, using pretrained resnet101 model.

For all examples in Week1, we have worked on Google Colab.

### Homework 1

In homework one, participants take an aligned hand image dataset with keypoint labels, and try to preprocess the dataset and make regression on the keypoint coordinates.


### Week2 - Natural Language Processing
-

### Homework 2
-


### Week 3 - Various Topics

We have worked on four problems:

* Hand Joint Coordinate Detection (solution of homework1) with CNNs, on Rovit Hand Pose Estimation Dataset.

* Anomaly Detection with LSTM Autoencoders, on Bearing Data Center dataset.

* Oil Price Prediction with LSTM, on oil price index.

* Occlusion Restoration with Conditional ImageGANs, on our custom dataset that is built upon UTK Faces.

We both used locally hosted Jupyter Notebooks and Google Colab.

### Homework 3

In homework three, participants practice on data acquisition (scraping) with a tool specialized on scraping news sites. They try to make use of an deep learning natural language processing library to obtain a premade language model. They also optionally develop their own models for language modelling.


### Week4 - 
-
